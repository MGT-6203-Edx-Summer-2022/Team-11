---
title: "QoQ Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries and Data

```{r libraries and data}

library(tidyverse)
library(corrplot)
library(lubridate)
library(anytime)
library(car)
library(leaps)
library(caret)
library(glmnet)
library(tidyr)
library(ggplot2)
library(ggpubr)

#-------------------------------------------------------------------------------
# Load Quarterly Data
#-------------------------------------------------------------------------------
# Load  data
df <-  read.csv("../Data/Macro_SP_QoQ.csv", fileEncoding="UTF-8-BOM")
df <- subset(df,select=-c(date))

# Convert date column to date format
# Macro_SP_QoQ <- as.Date(anytime(Macro_SP_QoQ$date))

# Remove Shiller_PE
Macro_SP_QoQ <- subset(df, select=-c(shiller_PE))

# summarize data
head(Macro_SP_QoQ)
```

## Exploratory Data Analysis

```{r EDA}
# histogram, QQ Plot, Box plot of SP500
hist(Macro_SP_QoQ$SP500, xlab='S&P Quarterly returns', 
     main='S&P Quarterly return distribution from 1967 to 2021',
     breaks = 40, col='lightblue', ylim=c(0,100))
qqnorm(Macro_SP_QoQ$SP500)

```

## PCA

```{r PCA}

SP500 <- Macro_SP_QoQ[22]

# PCA object
pca <- prcomp(Macro_SP_QoQ[,1:21], scale. = TRUE)
summary(pca)

# Calculate the variances and proportion of variances from the pca object
var <- pca$sdev^2
propvar <- var/sum(var)
cum <- cumsum(propvar)

# dataframe for plotting
df_plot <- data.frame(propvar, cum)

# Plots
p1 <- ggplot(data=df_plot, mapping=aes(x = as.numeric(row.names(df_plot)), y=propvar))+
          geom_col() + 
          ggtitle('Proportion of Variance Explained') +
          ylab('Proportion of Variance Explained') + xlab('Principal Component') +
          ylim(0,1)

p2 <- ggplot(data=df_plot, mapping=aes(x = as.numeric(row.names(df_plot)), y=cum))+
          geom_line(color='darkblue', size=0.8) + 
          ggtitle('Cumulative Proportion of Variance Explained') +
          ylab('Cumulative Proportion of Variance Explained') + xlab('Principal Component') +
          ylim(0,1)

                       
# Combine plots together and plot
ggarrange(p1, p2, ncol = 2, nrow = 1)
```

# Testing how many principal components is needed

```{r Testing different nro of components}

# Creating empty vectors to store Rsquared values with and without CV
Rsq <- vector(mode="numeric", length=21)    # Empty vector for Rsq
Rsq_cv <- vector(mode="numeric", length=21) # Empty vector for Rsq with CV


# Iterating over all the components
for (k in 1:21) {
  # Fitting model
  pcs_   <- as.data.frame(pca$x[, 1:k])
  data_  <- cbind(SP500, pcs_)
  
  # Model without CV
  model_ <- lm(SP500~., data = data_)
  # Calculating R-squared = 1 - SSEresiduals/SSEtotal
  SStot <- sum((Macro_SP_QoQ$SP500 - mean(Macro_SP_QoQ$SP500))^2)
  SSres_model <- sum(model_$residuals^2)
  Rsq[k] <- (1-SSres_model/SStot)
  
  # Model with 10-fold cross-validation
  train.control <- trainControl(method = "repeatedcv", number = 10, repeats=5)
  model_cv <- train(SP500~., data = data_, 
                    method = "lm", trControl = train.control)
  # Calculating R-squared 
  Rsq_cv[k] <- mean(model_cv$resample$Rsquared)
}

# Creating a dataframe or Rsquared with and without cross-validation
df_rsq <- data.frame(Rsq, Rsq_cv)
df_rsq
```

We achieve higher r-squared values after having 7 PCAs.

```{r PCA Plots}

# Plots
p3 <- ggplot(data=df_rsq, mapping=aes(x = as.numeric(row.names(df_rsq)), y=Rsq))+
  geom_col(fill='darkblue') + 
  ggtitle('Rsq') +
  ylab('Rsq') + xlab('Principal Component') +
  ylim(0, 0.5)

p4 <- ggplot(data=df_rsq, mapping=aes(x = as.numeric(row.names(df_rsq)), y=Rsq_cv))+
  geom_col(fill='darkblue') +  
  ggtitle('Rsq_cv') +
  ylab('Rsq_cv') + xlab('Principal Component') +
  ylim(0, 0.5)


# Combine plots together and plot
ggarrange(p3, p4, ncol = 2, nrow = 1)

```

# Regression With first 7 PCAs

```{r First 7 PCAs}

#Create new data matrix with first 7 PCs and SP500 QoQ change
df <- cbind(SP500, pca$x[,1:7]) 

# Create regression model
pca_model <- lm(SP500 ~., data = df)
summary(pca_model)


#-------------------------------------------------------------------------------
# With 10 fold cross-validation
train.control <- trainControl(method = "repeatedcv", number = 10, repeats=5)

pca_model_cv <- train(SP500 ~., data = df, 
                   method = "lm",trControl = train.control)

# Summary of the model
print(pca_model_cv)

```


## Testing the impact of lead-lag 
Testing if we achieve a better r-squared by leading and lagging SP500 QoQ by 1-2 quarters. Keeping 7 PCAs selected.

```{r Different Times}

# lead and lag by 2 quarters
df$SP500_lead1 <- lead(df$SP500, n=1)
df$SP500_lead2 <- lead(df$SP500, n=2)
df$SP500_lag1 <- lag(df$SP500, n=1)
df$SP500_lag2 <- lag(df$SP500, n=2)

# Drop na's
dfx <- drop_na(df,c(SP500_lead1, SP500_lead2, SP500_lag1, SP500_lag2))

# Fitting model with 7 principal components
model_lead1 <- train(SP500_lead1 ~., data = dfx, method = "lm", trControl = train.control)
model_lead2 <- train(SP500_lead2 ~., data = dfx, method = "lm", trControl = train.control)
model_lag1  <- train(SP500_lag1 ~., data = dfx, method = "lm", trControl = train.control)
model_lag2  <- train(SP500_lag2 ~., data = dfx, method = "lm", trControl = train.control)

# Print results
mean(pca_model_cv$resample$Rsquared)
mean(model_lead1$resample$Rsquared)
mean(model_lead2$resample$Rsquared)
mean(model_lag1$resample$Rsquared)
mean(model_lag2$resample$Rsquared)

```

We achieve the best results with the regular quarterly data.

Tranforming PCA coefficients for original variables.

```{r Coefficients of Original Variables}

# Transform the PCA coefficients into coefficients for the original variables
beta0 <- pca_model$coefficients[1]
betas <- pca_model$coefficients[2:8]
alphas <- pca$rotation[,1:7] %*% betas

### Unscaling data
originalAlpha <- alphas/sapply(Macro_SP_QoQ[,1:21],sd)
originalBeta0 <- beta0 - sum(alphas*sapply(Macro_SP_QoQ[,1:21],mean)/sapply(Macro_SP_QoQ[,1:21],sd))

originalAlpha

```

# Lasso Regression

```{r Lasso}

#Create new data matrix with PCAs and SP500 QoQ change
df <- cbind(pca$x, SP500) 

# Converting data frame to matrix, as this format is required in gmlnet
x <- as.matrix(df[,1:21])
y <- as.vector(df[,22])

# Lasso regression
model <- cv.glmnet(x, y, scale=TRUE, alpha = 1) # Lasso when alpha=1

# Find optimal lambda values that minimizes MSE
best_lambda <- model$lambda.min

# Find coefficients of best model
best_model <- glmnet(x, y, alpha=1, lambda=best_lambda)
coef(best_model)

```
```{r Regression with best components}

# Create regression model
lasso_pca <- lm(SP500 ~ PC1+PC2+PC3+PC5+PC6+PC8+PC9+PC10+PC12+PC15+PC19+PC21, data = df)
summary(lasso_pca)


#-------------------------------------------------------------------------------
# With 10 fold cross-validation
train.control <- trainControl(method = "repeatedcv", number = 10, repeats=5)

lasso_pca_cv <- train(SP500 ~., data = df, 
                   method = "lm",trControl = train.control)

# Summary of the model
print(lasso_pca_cv)

```


